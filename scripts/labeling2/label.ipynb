{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tensorflow soundfile numpy scipy soundfile numpy tensorflow-hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Using cached datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: filelock in /home/drama/projects/active/text2vital/venv/lib/python3.9/site-packages (from datasets) (3.16.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/drama/projects/active/text2vital/venv/lib/python3.9/site-packages (from datasets) (1.23.5)\n",
      "Collecting pyarrow>=15.0.0 (from datasets)\n",
      "  Downloading pyarrow-18.1.0-cp39-cp39-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in /home/drama/projects/active/text2vital/venv/lib/python3.9/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /home/drama/projects/active/text2vital/venv/lib/python3.9/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /home/drama/projects/active/text2vital/venv/lib/python3.9/site-packages (from datasets) (4.67.1)\n",
      "Collecting xxhash (from datasets)\n",
      "  Using cached xxhash-3.5.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Using cached multiprocess-0.70.16-py39-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
      "  Using cached fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting aiohttp (from datasets)\n",
      "  Downloading aiohttp-3.11.9-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in /home/drama/projects/active/text2vital/venv/lib/python3.9/site-packages (from datasets) (0.26.3)\n",
      "Requirement already satisfied: packaging in /home/drama/projects/active/text2vital/venv/lib/python3.9/site-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/drama/projects/active/text2vital/venv/lib/python3.9/site-packages (from datasets) (6.0.2)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->datasets)\n",
      "  Downloading aiohappyeyeballs-2.4.4-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets)\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting async-timeout<6.0,>=4.0 (from aiohttp->datasets)\n",
      "  Using cached async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp->datasets)\n",
      "  Using cached attrs-24.2.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets)\n",
      "  Using cached frozenlist-1.5.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\n",
      "  Using cached multidict-6.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp->datasets)\n",
      "  Downloading propcache-0.2.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.2 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp->datasets)\n",
      "  Downloading yarl-1.18.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (69 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/drama/projects/active/text2vital/venv/lib/python3.9/site-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/drama/projects/active/text2vital/venv/lib/python3.9/site-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/drama/projects/active/text2vital/venv/lib/python3.9/site-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/drama/projects/active/text2vital/venv/lib/python3.9/site-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/drama/projects/active/text2vital/venv/lib/python3.9/site-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/drama/projects/active/text2vital/venv/lib/python3.9/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/drama/projects/active/text2vital/venv/lib/python3.9/site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/drama/projects/active/text2vital/venv/lib/python3.9/site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/drama/projects/active/text2vital/venv/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Using cached datasets-3.1.0-py3-none-any.whl (480 kB)\n",
      "Using cached dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Using cached fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
      "Downloading aiohttp-3.11.9-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached multiprocess-0.70.16-py39-none-any.whl (133 kB)\n",
      "Downloading pyarrow-18.1.0-cp39-cp39-manylinux_2_28_x86_64.whl (40.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.1/40.1 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hUsing cached xxhash-3.5.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (193 kB)\n",
      "Downloading aiohappyeyeballs-2.4.4-py3-none-any.whl (14 kB)\n",
      "Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Using cached async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
      "Using cached attrs-24.2.0-py3-none-any.whl (63 kB)\n",
      "Using cached frozenlist-1.5.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (242 kB)\n",
      "Using cached multidict-6.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n",
      "Downloading propcache-0.2.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (208 kB)\n",
      "Downloading yarl-1.18.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (321 kB)\n",
      "Installing collected packages: xxhash, pyarrow, propcache, multidict, fsspec, frozenlist, dill, attrs, async-timeout, aiohappyeyeballs, yarl, multiprocess, aiosignal, aiohttp, datasets\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2024.10.0\n",
      "    Uninstalling fsspec-2024.10.0:\n",
      "      Successfully uninstalled fsspec-2024.10.0\n",
      "Successfully installed aiohappyeyeballs-2.4.4 aiohttp-3.11.9 aiosignal-1.3.1 async-timeout-5.0.1 attrs-24.2.0 datasets-3.1.0 dill-0.3.8 frozenlist-1.5.0 fsspec-2024.9.0 multidict-6.1.0 multiprocess-0.70.16 propcache-0.2.1 pyarrow-18.1.0 xxhash-3.5.0 yarl-1.18.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow_hub'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow_hub\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mhub\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcsv\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow_hub'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "import csv\n",
    "import io\n",
    "from scipy import signal\n",
    "import soundfile as sf\n",
    "\n",
    "model = hub.load('https://tfhub.dev/google/yamnet/1')\n",
    "\n",
    "def load_audio(filename, target_sample_rate=16000):\n",
    "    wav_data, sample_rate = sf.read(filename, dtype='float32')\n",
    "    if wav_data.ndim > 1:\n",
    "        wav_data = np.mean(wav_data, axis=1)\n",
    "    if sample_rate != target_sample_rate:\n",
    "        wav_data = signal.resample(wav_data, int(len(wav_data) * target_sample_rate / sample_rate))\n",
    "    return wav_data\n",
    "\n",
    "def class_names_from_csv(class_map_csv_text):\n",
    "    class_map_csv = io.StringIO(class_map_csv_text)\n",
    "    class_names = [display_name for (class_index, mid, display_name) in csv.reader(class_map_csv)]\n",
    "    return class_names[1:]\n",
    "\n",
    "def predict_labels(filename):\n",
    "    wav_data = load_audio(filename)\n",
    "    scores, embeddings, spectrogram = model(wav_data)\n",
    "    \n",
    "    class_map_path = model.class_map_path().numpy().decode('utf-8')\n",
    "    class_map_csv_text = tf.io.read_file(class_map_path).numpy().decode('utf-8')\n",
    "    class_names = class_names_from_csv(class_map_csv_text)\n",
    "\n",
    "    mean_scores = tf.reduce_mean(scores, axis=0).numpy()\n",
    "    top5_indices = np.argsort(mean_scores)[::-1][:5]\n",
    "    top5_labels = [class_names[i] for i in top5_indices]\n",
    "    return top5_labels\n",
    "\n",
    "filename = \"prev.mp3\"\n",
    "labels = predict_labels(filename)\n",
    "print(\"Предсказанные метки:\", labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m     description \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mЗвук с характеристиками: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(labels)\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m description\n\u001b[0;32m----> 5\u001b[0m description \u001b[38;5;241m=\u001b[39m generate_description(\u001b[43mlabels\u001b[49m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mОписание:\u001b[39m\u001b[38;5;124m\"\u001b[39m, description)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'labels' is not defined"
     ]
    }
   ],
   "source": [
    "def generate_description(labels):\n",
    "    description = \"Звук с характеристиками: \" + \", \".join(labels)\n",
    "    return description\n",
    "\n",
    "description = generate_description(labels)\n",
    "print(\"Описание:\", description)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install transformers librosa torch ipywidgets torchvision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-02 11:44:06.391982: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-02 11:44:06.590080: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1733129046.663777  945392 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1733129046.685214  945392 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-02 11:44:06.877638: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшее описание для данного аудио: buzzy, distorted bass with a heavy punch, grounding intense tracks\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import librosa\n",
    "import torch\n",
    "from transformers import AutoModel, AutoProcessor\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\"laion/clap-htsat-unfused\")\n",
    "model = AutoModel.from_pretrained(\"laion/clap-htsat-unfused\")\n",
    "\n",
    "def load_audio(filename, target_sr=48000):\n",
    "    audio, sr = librosa.load(filename, sr=target_sr)\n",
    "    return audio, sr\n",
    "\n",
    "def get_best_description(audio_file, descriptions):\n",
    "    audio, sr = load_audio(audio_file)\n",
    "    audio_inputs = processor(audios=audio, sampling_rate=sr, return_tensors=\"pt\", padding=True)\n",
    "    with torch.no_grad():\n",
    "        audio_features = model.get_audio_features(**audio_inputs)\n",
    "    text_inputs = processor(text=descriptions, return_tensors=\"pt\", padding=True)\n",
    "    with torch.no_grad():\n",
    "        text_features = model.get_text_features(**text_inputs)\n",
    "    similarities = torch.nn.functional.cosine_similarity(audio_features, text_features)\n",
    "    best_match_index = similarities.argmax().item()\n",
    "    best_match_description = descriptions[best_match_index]\n",
    "    return best_match_description\n",
    "\n",
    "audio_file = \"prev.mp3\"\n",
    "# audio_file = \"6036a3dfb3944_c.mp3\"\n",
    "# audio_file = \"62e030c5cf5ca_c.mp3\"\n",
    "with open('descriptions.json', 'r') as file:\n",
    "    descriptions = json.load(file)\n",
    "\n",
    "best_description = get_best_description(audio_file, descriptions)\n",
    "print(\"Лучшее описание для данного аудио:\", best_description)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Создан labeled_data/1.json\n",
      "Создан labeled_data/2.json\n",
      "Создан labeled_data/3.json\n",
      "Создан labeled_data/4.json\n",
      "Создан labeled_data/5.json\n",
      "Создан labeled_data/6.json\n",
      "Создан labeled_data/7.json\n",
      "Создан labeled_data/8.json\n",
      "Создан labeled_data/9.json\n",
      "Создан labeled_data/10.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import librosa\n",
    "import torch\n",
    "from transformers import AutoModel, AutoProcessor\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\"laion/clap-htsat-unfused\")\n",
    "model = AutoModel.from_pretrained(\"laion/clap-htsat-unfused\")\n",
    "\n",
    "def load_audio(filename, target_sr=48000):\n",
    "    audio, sr = librosa.load(filename, sr=target_sr)\n",
    "    return audio, sr\n",
    "\n",
    "def get_best_description(audio_file, descriptions):\n",
    "    audio, sr = load_audio(audio_file)\n",
    "    audio_inputs = processor(audios=audio, sampling_rate=sr, return_tensors=\"pt\", padding=True)\n",
    "    with torch.no_grad():\n",
    "        audio_features = model.get_audio_features(**audio_inputs)\n",
    "    text_inputs = processor(text=descriptions, return_tensors=\"pt\", padding=True)\n",
    "    with torch.no_grad():\n",
    "        text_features = model.get_text_features(**text_inputs)\n",
    "    similarities = torch.nn.functional.cosine_similarity(audio_features, text_features)\n",
    "    best_match_index = similarities.argmax().item()\n",
    "    best_match_description = descriptions[best_match_index]\n",
    "    return best_match_description\n",
    "\n",
    "with open('descriptions.json', 'r') as file:\n",
    "    descriptions = json.load(file)\n",
    "\n",
    "def process_folders(data_dir, labeled_dir, n, k):\n",
    "    os.makedirs(labeled_dir, exist_ok=True)\n",
    "\n",
    "    for folder_num in range(n, k + 1):\n",
    "        folder_name = f\"{folder_num:04d}\"\n",
    "        folder_path = os.path.join(data_dir, folder_name)\n",
    "\n",
    "        if not os.path.isdir(folder_path):\n",
    "            print(f\"Папка {folder_path} не существует, пропускаем.\")\n",
    "            continue\n",
    "\n",
    "        params_path = os.path.join(folder_path, \"params.json\")\n",
    "        audio_file = os.path.join(folder_path, \"prev.mp3\")\n",
    "        \n",
    "        vital_file = None\n",
    "        for file_name in os.listdir(folder_path):\n",
    "            if file_name.endswith(\".vital\"):\n",
    "                vital_file = os.path.join(folder_path, file_name)\n",
    "                break\n",
    "\n",
    "        if not os.path.isfile(params_path) or not os.path.isfile(audio_file) or not vital_file:\n",
    "            print(f\"Отсутствует params.json, prev.mp3 или .vital файл в {folder_path}, пропускаем.\")\n",
    "            continue\n",
    "\n",
    "        with open(params_path, 'r') as file:\n",
    "            params = json.load(file)\n",
    "\n",
    "        try:\n",
    "            with open(vital_file, 'r') as file:\n",
    "                vital_content = file.read().strip()\n",
    "                if not vital_content:\n",
    "                    print(f\"Файл {vital_file} пуст, пропускаем.\")\n",
    "                    continue\n",
    "                vital_data = json.loads(vital_content)\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Файл {vital_file} не является валидным JSON, пропускаем.\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            best_description = get_best_description(audio_file, descriptions)\n",
    "            params[\"description\"] = best_description\n",
    "            params[\"preset\"] = vital_data\n",
    "\n",
    "            output_file = os.path.join(labeled_dir, f\"{folder_num}.json\")\n",
    "            with open(output_file, 'w') as file:\n",
    "                json.dump(params, file, indent=4)\n",
    "\n",
    "            print(f\"Создан {output_file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка при обработке {folder_path}: {e}\")\n",
    "\n",
    "data_directory = \"../data\"\n",
    "labeled_directory = \"labeled_data\"\n",
    "n = 1\n",
    "k = 10\n",
    "process_folders(data_directory, labeled_directory, n, k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Создан labeled_data_music/1.json\n",
      "Создан labeled_data_music/2.json\n",
      "Создан labeled_data_music/3.json\n",
      "Создан labeled_data_music/4.json\n",
      "Создан labeled_data_music/5.json\n",
      "Создан labeled_data_music/6.json\n",
      "Создан labeled_data_music/7.json\n",
      "Создан labeled_data_music/8.json\n",
      "Создан labeled_data_music/9.json\n",
      "Создан labeled_data_music/10.json\n",
      "Создан labeled_data_music/11.json\n",
      "Создан labeled_data_music/12.json\n",
      "Создан labeled_data_music/13.json\n",
      "Создан labeled_data_music/14.json\n",
      "Файл ../data/0015/Snare_Generator.vital пуст, пропускаем.\n",
      "Создан labeled_data_music/16.json\n",
      "Создан labeled_data_music/17.json\n",
      "Создан labeled_data_music/18.json\n",
      "Создан labeled_data_music/19.json\n",
      "Создан labeled_data_music/20.json\n",
      "Создан labeled_data_music/21.json\n",
      "Создан labeled_data_music/22.json\n",
      "Создан labeled_data_music/23.json\n",
      "Создан labeled_data_music/24.json\n",
      "Создан labeled_data_music/25.json\n",
      "Создан labeled_data_music/26.json\n",
      "Создан labeled_data_music/27.json\n",
      "Создан labeled_data_music/28.json\n",
      "Создан labeled_data_music/29.json\n",
      "Создан labeled_data_music/30.json\n",
      "Создан labeled_data_music/31.json\n",
      "Создан labeled_data_music/32.json\n",
      "Создан labeled_data_music/33.json\n",
      "Создан labeled_data_music/34.json\n",
      "Создан labeled_data_music/35.json\n",
      "Создан labeled_data_music/36.json\n",
      "Создан labeled_data_music/37.json\n",
      "Создан labeled_data_music/38.json\n",
      "Создан labeled_data_music/39.json\n",
      "Создан labeled_data_music/40.json\n",
      "Создан labeled_data_music/41.json\n",
      "Создан labeled_data_music/42.json\n",
      "Создан labeled_data_music/43.json\n",
      "Создан labeled_data_music/44.json\n",
      "Создан labeled_data_music/45.json\n",
      "Создан labeled_data_music/46.json\n",
      "Создан labeled_data_music/47.json\n",
      "Создан labeled_data_music/48.json\n",
      "Создан labeled_data_music/49.json\n",
      "Создан labeled_data_music/50.json\n",
      "Создан labeled_data_music/51.json\n",
      "Создан labeled_data_music/52.json\n",
      "Создан labeled_data_music/53.json\n",
      "Создан labeled_data_music/54.json\n",
      "Создан labeled_data_music/55.json\n",
      "Создан labeled_data_music/56.json\n",
      "Создан labeled_data_music/57.json\n",
      "Создан labeled_data_music/58.json\n",
      "Создан labeled_data_music/59.json\n",
      "Создан labeled_data_music/60.json\n",
      "Создан labeled_data_music/61.json\n",
      "Создан labeled_data_music/62.json\n",
      "Создан labeled_data_music/63.json\n",
      "Создан labeled_data_music/64.json\n",
      "Создан labeled_data_music/65.json\n",
      "Создан labeled_data_music/66.json\n",
      "Создан labeled_data_music/67.json\n",
      "Создан labeled_data_music/68.json\n",
      "Создан labeled_data_music/69.json\n",
      "Создан labeled_data_music/70.json\n",
      "Создан labeled_data_music/71.json\n",
      "Создан labeled_data_music/72.json\n",
      "Создан labeled_data_music/73.json\n",
      "Создан labeled_data_music/74.json\n",
      "Создан labeled_data_music/75.json\n",
      "Создан labeled_data_music/76.json\n",
      "Создан labeled_data_music/77.json\n",
      "Создан labeled_data_music/78.json\n",
      "Создан labeled_data_music/79.json\n",
      "Создан labeled_data_music/80.json\n",
      "Создан labeled_data_music/81.json\n",
      "Создан labeled_data_music/82.json\n",
      "Создан labeled_data_music/83.json\n",
      "Создан labeled_data_music/84.json\n",
      "Создан labeled_data_music/85.json\n",
      "Создан labeled_data_music/86.json\n",
      "Создан labeled_data_music/87.json\n",
      "Создан labeled_data_music/88.json\n",
      "Создан labeled_data_music/89.json\n",
      "Создан labeled_data_music/90.json\n",
      "Создан labeled_data_music/91.json\n",
      "Создан labeled_data_music/92.json\n",
      "Создан labeled_data_music/93.json\n",
      "Создан labeled_data_music/94.json\n",
      "Создан labeled_data_music/95.json\n",
      "Создан labeled_data_music/96.json\n",
      "Создан labeled_data_music/97.json\n",
      "Создан labeled_data_music/98.json\n",
      "Создан labeled_data_music/99.json\n",
      "Создан labeled_data_music/100.json\n",
      "Создан labeled_data_music/101.json\n",
      "Создан labeled_data_music/102.json\n",
      "Создан labeled_data_music/103.json\n",
      "Создан labeled_data_music/104.json\n",
      "Создан labeled_data_music/105.json\n",
      "Создан labeled_data_music/106.json\n",
      "Создан labeled_data_music/107.json\n",
      "Создан labeled_data_music/108.json\n",
      "Создан labeled_data_music/109.json\n",
      "Создан labeled_data_music/110.json\n",
      "Создан labeled_data_music/111.json\n",
      "Создан labeled_data_music/112.json\n",
      "Создан labeled_data_music/113.json\n",
      "Создан labeled_data_music/114.json\n",
      "Создан labeled_data_music/115.json\n",
      "Создан labeled_data_music/116.json\n",
      "Создан labeled_data_music/117.json\n",
      "Создан labeled_data_music/118.json\n",
      "Создан labeled_data_music/119.json\n",
      "Создан labeled_data_music/120.json\n",
      "Создан labeled_data_music/121.json\n",
      "Создан labeled_data_music/122.json\n",
      "Создан labeled_data_music/123.json\n",
      "Создан labeled_data_music/124.json\n",
      "Создан labeled_data_music/125.json\n",
      "Создан labeled_data_music/126.json\n",
      "Создан labeled_data_music/127.json\n",
      "Создан labeled_data_music/128.json\n",
      "Создан labeled_data_music/129.json\n",
      "Создан labeled_data_music/130.json\n",
      "Создан labeled_data_music/131.json\n",
      "Создан labeled_data_music/132.json\n",
      "Создан labeled_data_music/133.json\n",
      "Создан labeled_data_music/134.json\n",
      "Создан labeled_data_music/135.json\n",
      "Создан labeled_data_music/136.json\n",
      "Создан labeled_data_music/137.json\n",
      "Создан labeled_data_music/138.json\n",
      "Создан labeled_data_music/139.json\n",
      "Создан labeled_data_music/140.json\n",
      "Создан labeled_data_music/141.json\n",
      "Создан labeled_data_music/142.json\n",
      "Создан labeled_data_music/143.json\n",
      "Создан labeled_data_music/144.json\n",
      "Создан labeled_data_music/145.json\n",
      "Создан labeled_data_music/146.json\n",
      "Создан labeled_data_music/147.json\n",
      "Создан labeled_data_music/148.json\n",
      "Создан labeled_data_music/149.json\n",
      "Создан labeled_data_music/150.json\n",
      "Создан labeled_data_music/151.json\n",
      "Создан labeled_data_music/152.json\n",
      "Создан labeled_data_music/153.json\n",
      "Создан labeled_data_music/154.json\n",
      "Создан labeled_data_music/155.json\n",
      "Создан labeled_data_music/156.json\n",
      "Создан labeled_data_music/157.json\n",
      "Создан labeled_data_music/158.json\n",
      "Создан labeled_data_music/159.json\n",
      "Создан labeled_data_music/160.json\n",
      "Создан labeled_data_music/161.json\n",
      "Создан labeled_data_music/162.json\n",
      "Создан labeled_data_music/163.json\n",
      "Создан labeled_data_music/164.json\n",
      "Создан labeled_data_music/165.json\n",
      "Создан labeled_data_music/166.json\n",
      "Создан labeled_data_music/167.json\n",
      "Создан labeled_data_music/168.json\n",
      "Создан labeled_data_music/169.json\n",
      "Создан labeled_data_music/170.json\n",
      "Создан labeled_data_music/171.json\n",
      "Создан labeled_data_music/172.json\n",
      "Создан labeled_data_music/173.json\n",
      "Создан labeled_data_music/174.json\n",
      "Создан labeled_data_music/175.json\n",
      "Создан labeled_data_music/176.json\n",
      "Создан labeled_data_music/177.json\n",
      "Создан labeled_data_music/178.json\n",
      "Создан labeled_data_music/179.json\n",
      "Создан labeled_data_music/180.json\n",
      "Создан labeled_data_music/181.json\n",
      "Создан labeled_data_music/182.json\n",
      "Создан labeled_data_music/183.json\n",
      "Создан labeled_data_music/184.json\n",
      "Создан labeled_data_music/185.json\n",
      "Создан labeled_data_music/186.json\n",
      "Создан labeled_data_music/187.json\n",
      "Создан labeled_data_music/188.json\n",
      "Создан labeled_data_music/189.json\n",
      "Создан labeled_data_music/190.json\n",
      "Создан labeled_data_music/191.json\n",
      "Создан labeled_data_music/192.json\n",
      "Создан labeled_data_music/193.json\n",
      "Создан labeled_data_music/194.json\n",
      "Создан labeled_data_music/195.json\n",
      "Создан labeled_data_music/196.json\n",
      "Создан labeled_data_music/197.json\n",
      "Создан labeled_data_music/198.json\n",
      "Создан labeled_data_music/199.json\n",
      "Создан labeled_data_music/200.json\n",
      "Создан labeled_data_music/201.json\n",
      "Создан labeled_data_music/202.json\n",
      "Создан labeled_data_music/203.json\n",
      "Создан labeled_data_music/204.json\n",
      "Создан labeled_data_music/205.json\n",
      "Создан labeled_data_music/206.json\n",
      "Создан labeled_data_music/207.json\n",
      "Создан labeled_data_music/208.json\n",
      "Создан labeled_data_music/209.json\n",
      "Создан labeled_data_music/210.json\n",
      "Создан labeled_data_music/211.json\n",
      "Создан labeled_data_music/212.json\n",
      "Создан labeled_data_music/213.json\n",
      "Создан labeled_data_music/214.json\n",
      "Создан labeled_data_music/215.json\n",
      "Создан labeled_data_music/216.json\n",
      "Создан labeled_data_music/217.json\n",
      "Создан labeled_data_music/218.json\n",
      "Создан labeled_data_music/219.json\n",
      "Создан labeled_data_music/220.json\n",
      "Создан labeled_data_music/221.json\n",
      "Создан labeled_data_music/222.json\n",
      "Создан labeled_data_music/223.json\n",
      "Создан labeled_data_music/224.json\n",
      "Создан labeled_data_music/225.json\n",
      "Создан labeled_data_music/226.json\n",
      "Создан labeled_data_music/227.json\n",
      "Создан labeled_data_music/228.json\n",
      "Создан labeled_data_music/229.json\n",
      "Создан labeled_data_music/230.json\n",
      "Создан labeled_data_music/231.json\n",
      "Создан labeled_data_music/232.json\n",
      "Создан labeled_data_music/233.json\n",
      "Создан labeled_data_music/234.json\n",
      "Создан labeled_data_music/235.json\n",
      "Создан labeled_data_music/236.json\n",
      "Создан labeled_data_music/237.json\n",
      "Создан labeled_data_music/238.json\n",
      "Создан labeled_data_music/239.json\n",
      "Создан labeled_data_music/240.json\n",
      "Создан labeled_data_music/241.json\n",
      "Создан labeled_data_music/242.json\n",
      "Создан labeled_data_music/243.json\n",
      "Создан labeled_data_music/244.json\n",
      "Создан labeled_data_music/245.json\n",
      "Создан labeled_data_music/246.json\n",
      "Создан labeled_data_music/247.json\n",
      "Создан labeled_data_music/248.json\n",
      "Создан labeled_data_music/249.json\n",
      "Создан labeled_data_music/250.json\n",
      "Создан labeled_data_music/251.json\n",
      "Создан labeled_data_music/252.json\n",
      "Создан labeled_data_music/253.json\n",
      "Создан labeled_data_music/254.json\n",
      "Создан labeled_data_music/255.json\n",
      "Создан labeled_data_music/256.json\n",
      "Создан labeled_data_music/257.json\n",
      "Создан labeled_data_music/258.json\n",
      "Создан labeled_data_music/259.json\n",
      "Создан labeled_data_music/260.json\n",
      "Создан labeled_data_music/261.json\n",
      "Создан labeled_data_music/262.json\n",
      "Создан labeled_data_music/263.json\n",
      "Создан labeled_data_music/264.json\n",
      "Создан labeled_data_music/265.json\n",
      "Создан labeled_data_music/266.json\n",
      "Создан labeled_data_music/267.json\n",
      "Создан labeled_data_music/268.json\n",
      "Создан labeled_data_music/269.json\n",
      "Создан labeled_data_music/270.json\n",
      "Создан labeled_data_music/271.json\n",
      "Создан labeled_data_music/272.json\n",
      "Создан labeled_data_music/273.json\n",
      "Создан labeled_data_music/274.json\n",
      "Создан labeled_data_music/275.json\n",
      "Создан labeled_data_music/276.json\n",
      "Создан labeled_data_music/277.json\n",
      "Создан labeled_data_music/278.json\n",
      "Создан labeled_data_music/279.json\n",
      "Создан labeled_data_music/280.json\n",
      "Создан labeled_data_music/281.json\n",
      "Создан labeled_data_music/282.json\n",
      "Создан labeled_data_music/283.json\n",
      "Создан labeled_data_music/284.json\n",
      "Создан labeled_data_music/285.json\n",
      "Создан labeled_data_music/286.json\n",
      "Создан labeled_data_music/287.json\n",
      "Создан labeled_data_music/288.json\n",
      "Создан labeled_data_music/289.json\n",
      "Создан labeled_data_music/290.json\n",
      "Создан labeled_data_music/291.json\n",
      "Создан labeled_data_music/292.json\n",
      "Создан labeled_data_music/293.json\n",
      "Создан labeled_data_music/294.json\n",
      "Создан labeled_data_music/295.json\n",
      "Создан labeled_data_music/296.json\n",
      "Создан labeled_data_music/297.json\n",
      "Создан labeled_data_music/298.json\n",
      "Создан labeled_data_music/299.json\n",
      "Создан labeled_data_music/300.json\n",
      "Создан labeled_data_music/301.json\n",
      "Создан labeled_data_music/302.json\n",
      "Создан labeled_data_music/303.json\n",
      "Создан labeled_data_music/304.json\n",
      "Создан labeled_data_music/305.json\n",
      "Создан labeled_data_music/306.json\n",
      "Создан labeled_data_music/307.json\n",
      "Создан labeled_data_music/308.json\n",
      "Создан labeled_data_music/309.json\n",
      "Создан labeled_data_music/310.json\n",
      "Создан labeled_data_music/311.json\n",
      "Создан labeled_data_music/312.json\n",
      "Создан labeled_data_music/313.json\n",
      "Создан labeled_data_music/314.json\n",
      "Создан labeled_data_music/315.json\n",
      "Создан labeled_data_music/316.json\n",
      "Создан labeled_data_music/317.json\n",
      "Создан labeled_data_music/318.json\n",
      "Создан labeled_data_music/319.json\n",
      "Создан labeled_data_music/320.json\n",
      "Создан labeled_data_music/321.json\n",
      "Создан labeled_data_music/322.json\n",
      "Создан labeled_data_music/323.json\n",
      "Создан labeled_data_music/324.json\n",
      "Создан labeled_data_music/325.json\n",
      "Создан labeled_data_music/326.json\n",
      "Создан labeled_data_music/327.json\n",
      "Создан labeled_data_music/328.json\n",
      "Создан labeled_data_music/329.json\n",
      "Создан labeled_data_music/330.json\n",
      "Создан labeled_data_music/331.json\n",
      "Создан labeled_data_music/332.json\n",
      "Создан labeled_data_music/333.json\n",
      "Создан labeled_data_music/334.json\n",
      "Создан labeled_data_music/335.json\n",
      "Создан labeled_data_music/336.json\n",
      "Создан labeled_data_music/337.json\n",
      "Создан labeled_data_music/338.json\n",
      "Создан labeled_data_music/339.json\n",
      "Создан labeled_data_music/340.json\n",
      "Создан labeled_data_music/341.json\n",
      "Создан labeled_data_music/342.json\n",
      "Создан labeled_data_music/343.json\n",
      "Создан labeled_data_music/344.json\n",
      "Создан labeled_data_music/345.json\n",
      "Создан labeled_data_music/346.json\n",
      "Создан labeled_data_music/347.json\n",
      "Создан labeled_data_music/348.json\n",
      "Создан labeled_data_music/349.json\n",
      "Создан labeled_data_music/350.json\n",
      "Создан labeled_data_music/351.json\n",
      "Создан labeled_data_music/352.json\n",
      "Создан labeled_data_music/353.json\n",
      "Создан labeled_data_music/354.json\n",
      "Создан labeled_data_music/355.json\n",
      "Создан labeled_data_music/356.json\n",
      "Создан labeled_data_music/357.json\n",
      "Создан labeled_data_music/358.json\n",
      "Создан labeled_data_music/359.json\n",
      "Создан labeled_data_music/360.json\n",
      "Создан labeled_data_music/361.json\n",
      "Создан labeled_data_music/362.json\n",
      "Создан labeled_data_music/363.json\n",
      "Создан labeled_data_music/364.json\n",
      "Создан labeled_data_music/365.json\n",
      "Создан labeled_data_music/366.json\n",
      "Создан labeled_data_music/367.json\n",
      "Создан labeled_data_music/368.json\n",
      "Создан labeled_data_music/369.json\n",
      "Создан labeled_data_music/370.json\n",
      "Создан labeled_data_music/371.json\n",
      "Создан labeled_data_music/372.json\n",
      "Создан labeled_data_music/373.json\n",
      "Создан labeled_data_music/374.json\n",
      "Создан labeled_data_music/375.json\n",
      "Создан labeled_data_music/376.json\n",
      "Создан labeled_data_music/377.json\n",
      "Создан labeled_data_music/378.json\n",
      "Создан labeled_data_music/379.json\n",
      "Создан labeled_data_music/380.json\n",
      "Создан labeled_data_music/381.json\n",
      "Создан labeled_data_music/382.json\n",
      "Создан labeled_data_music/383.json\n",
      "Создан labeled_data_music/384.json\n",
      "Создан labeled_data_music/385.json\n",
      "Создан labeled_data_music/386.json\n",
      "Создан labeled_data_music/387.json\n",
      "Создан labeled_data_music/388.json\n",
      "Создан labeled_data_music/389.json\n",
      "Создан labeled_data_music/390.json\n",
      "Создан labeled_data_music/391.json\n",
      "Создан labeled_data_music/392.json\n",
      "Создан labeled_data_music/393.json\n",
      "Создан labeled_data_music/394.json\n",
      "Создан labeled_data_music/395.json\n",
      "Создан labeled_data_music/396.json\n",
      "Создан labeled_data_music/397.json\n",
      "Создан labeled_data_music/398.json\n",
      "Создан labeled_data_music/399.json\n",
      "Создан labeled_data_music/400.json\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 88\u001b[0m\n\u001b[1;32m     86\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     87\u001b[0m k \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m500\u001b[39m\n\u001b[0;32m---> 88\u001b[0m \u001b[43mprocess_folders\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_directory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabeled_directory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[15], line 72\u001b[0m, in \u001b[0;36mprocess_folders\u001b[0;34m(data_dir, labeled_dir, n, k)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 72\u001b[0m     best_description \u001b[38;5;241m=\u001b[39m \u001b[43mget_best_description\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdescriptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m     params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdescription\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m best_description\n\u001b[1;32m     74\u001b[0m     params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpreset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m vital_data\n",
      "Cell \u001b[0;32mIn[15], line 24\u001b[0m, in \u001b[0;36mget_best_description\u001b[0;34m(audio_file, descriptions)\u001b[0m\n\u001b[1;32m     22\u001b[0m text_inputs \u001b[38;5;241m=\u001b[39m processor(text\u001b[38;5;241m=\u001b[39mdescriptions, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 24\u001b[0m     text_features \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_text_features\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtext_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m similarities \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mcosine_similarity(audio_features, text_features)\n\u001b[1;32m     26\u001b[0m best_match_index \u001b[38;5;241m=\u001b[39m similarities\u001b[38;5;241m.\u001b[39margmax()\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/projects/active/text2vital/venv/lib/python3.9/site-packages/transformers/models/clap/modeling_clap.py:1992\u001b[0m, in \u001b[0;36mClapModel.get_text_features\u001b[0;34m(self, input_ids, attention_mask, position_ids, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1987\u001b[0m output_hidden_states \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1988\u001b[0m     output_hidden_states \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39moutput_hidden_states\n\u001b[1;32m   1989\u001b[0m )\n\u001b[1;32m   1990\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1992\u001b[0m text_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1993\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1994\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1995\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1996\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1997\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1998\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1999\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2001\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m text_outputs[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m text_outputs\u001b[38;5;241m.\u001b[39mpooler_output\n\u001b[1;32m   2002\u001b[0m text_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext_projection(pooled_output)\n",
      "File \u001b[0;32m~/projects/active/text2vital/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/active/text2vital/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/projects/active/text2vital/venv/lib/python3.9/site-packages/transformers/models/clap/modeling_clap.py:1895\u001b[0m, in \u001b[0;36mClapTextModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1886\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m   1888\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[1;32m   1889\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   1890\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1893\u001b[0m     past_key_values_length\u001b[38;5;241m=\u001b[39mpast_key_values_length,\n\u001b[1;32m   1894\u001b[0m )\n\u001b[0;32m-> 1895\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1896\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1897\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1898\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1899\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1900\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1901\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1902\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1903\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1904\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1905\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1906\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1907\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1908\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/active/text2vital/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/active/text2vital/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/projects/active/text2vital/venv/lib/python3.9/site-packages/transformers/models/clap/modeling_clap.py:1607\u001b[0m, in \u001b[0;36mClapTextEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1596\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m   1597\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m   1598\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1604\u001b[0m         output_attentions,\n\u001b[1;32m   1605\u001b[0m     )\n\u001b[1;32m   1606\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1607\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1608\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1609\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1610\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1611\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1612\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1613\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1614\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1615\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1617\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1618\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/projects/active/text2vital/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/active/text2vital/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/projects/active/text2vital/venv/lib/python3.9/site-packages/transformers/models/clap/modeling_clap.py:1538\u001b[0m, in \u001b[0;36mClapTextLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m   1535\u001b[0m     cross_attn_present_key_value \u001b[38;5;241m=\u001b[39m cross_attention_outputs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   1536\u001b[0m     present_key_value \u001b[38;5;241m=\u001b[39m present_key_value \u001b[38;5;241m+\u001b[39m cross_attn_present_key_value\n\u001b[0;32m-> 1538\u001b[0m layer_output \u001b[38;5;241m=\u001b[39m \u001b[43mapply_chunking_to_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1539\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed_forward_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchunk_size_feed_forward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseq_len_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\n\u001b[1;32m   1540\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1541\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (layer_output,) \u001b[38;5;241m+\u001b[39m outputs\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;66;03m# if decoder, return the attn key/values as the last output\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/active/text2vital/venv/lib/python3.9/site-packages/transformers/pytorch_utils.py:248\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;66;03m# concatenate output at same dimension\u001b[39;00m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(output_chunks, dim\u001b[38;5;241m=\u001b[39mchunk_dim)\n\u001b[0;32m--> 248\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minput_tensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/active/text2vital/venv/lib/python3.9/site-packages/transformers/models/clap/modeling_clap.py:1550\u001b[0m, in \u001b[0;36mClapTextLayer.feed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m   1549\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfeed_forward_chunk\u001b[39m(\u001b[38;5;28mself\u001b[39m, attention_output):\n\u001b[0;32m-> 1550\u001b[0m     intermediate_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintermediate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattention_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1551\u001b[0m     layer_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(intermediate_output, attention_output)\n\u001b[1;32m   1552\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m layer_output\n",
      "File \u001b[0;32m~/projects/active/text2vital/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/active/text2vital/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import librosa\n",
    "from datasets import load_dataset\n",
    "from transformers import ClapModel, ClapProcessor\n",
    "\n",
    "librispeech_dummy = load_dataset(\"hf-internal-testing/librispeech_asr_dummy\", \"clean\", split=\"validation\")\n",
    "audio_sample = librispeech_dummy[0]\n",
    "\n",
    "model = ClapModel.from_pretrained(\"laion/larger_clap_music\")\n",
    "processor = ClapProcessor.from_pretrained(\"laion/larger_clap_music\")\n",
    "\n",
    "def load_audio(filename, target_sr=48000):\n",
    "    audio, sr = librosa.load(filename, sr=target_sr)\n",
    "    return audio, sr\n",
    "\n",
    "def get_best_description(audio_file, descriptions):\n",
    "    audio, sr = load_audio(audio_file)\n",
    "    audio_inputs = processor(audios=audio, sampling_rate=sr, return_tensors=\"pt\", padding=True)\n",
    "    with torch.no_grad():\n",
    "        audio_features = model.get_audio_features(**audio_inputs)\n",
    "    text_inputs = processor(text=descriptions, return_tensors=\"pt\", padding=True)\n",
    "    with torch.no_grad():\n",
    "        text_features = model.get_text_features(**text_inputs)\n",
    "    similarities = torch.nn.functional.cosine_similarity(audio_features, text_features)\n",
    "    best_match_index = similarities.argmax().item()\n",
    "    best_match_description = descriptions[best_match_index]\n",
    "    return best_match_description\n",
    "\n",
    "with open('descriptions.json', 'r') as file:\n",
    "    descriptions = json.load(file)\n",
    "\n",
    "def process_folders(data_dir, labeled_dir, n, k):\n",
    "    os.makedirs(labeled_dir, exist_ok=True)\n",
    "\n",
    "    for folder_num in range(n, k + 1):\n",
    "        folder_name = f\"{folder_num:04d}\"\n",
    "        folder_path = os.path.join(data_dir, folder_name)\n",
    "\n",
    "        if not os.path.isdir(folder_path):\n",
    "            print(f\"Папка {folder_path} не существует, пропускаем.\")\n",
    "            continue\n",
    "\n",
    "        params_path = os.path.join(folder_path, \"params.json\")\n",
    "        audio_file = os.path.join(folder_path, \"prev.mp3\")\n",
    "\n",
    "        vital_file = None\n",
    "        for file_name in os.listdir(folder_path):\n",
    "            if file_name.endswith(\".vital\"):\n",
    "                vital_file = os.path.join(folder_path, file_name)\n",
    "                break\n",
    "\n",
    "        if not os.path.isfile(params_path) or not os.path.isfile(audio_file) or not vital_file:\n",
    "            print(f\"Отсутствует params.json, prev.mp3 или .vital файл в {folder_path}, пропускаем.\")\n",
    "            continue\n",
    "\n",
    "        with open(params_path, 'r') as file:\n",
    "            params = json.load(file)\n",
    "\n",
    "        try:\n",
    "            with open(vital_file, 'r') as file:\n",
    "                vital_content = file.read().strip()\n",
    "                if not vital_content:\n",
    "                    print(f\"Файл {vital_file} пуст, пропускаем.\")\n",
    "                    continue\n",
    "                vital_data = json.loads(vital_content)\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Файл {vital_file} не является валидным JSON, пропускаем.\")\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            best_description = get_best_description(audio_file, descriptions)\n",
    "            params[\"description\"] = best_description\n",
    "            params[\"preset\"] = vital_data\n",
    "\n",
    "            output_file = os.path.join(labeled_dir, f\"{folder_num}.json\")\n",
    "            with open(output_file, 'w') as file:\n",
    "                json.dump(params, file, indent=4)\n",
    "\n",
    "            print(f\"Создан {output_file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка при обработке {folder_path}: {e}\")\n",
    "\n",
    "data_directory = \"../data\"\n",
    "labeled_directory = \"labeled_data_music\"\n",
    "n = 1\n",
    "k = 500\n",
    "process_folders(data_directory, labeled_directory, n, k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Создан labeled_data_general/1.json\n",
      "Создан labeled_data_general/2.json\n",
      "Создан labeled_data_general/3.json\n",
      "Создан labeled_data_general/4.json\n",
      "Создан labeled_data_general/5.json\n",
      "Создан labeled_data_general/6.json\n",
      "Создан labeled_data_general/7.json\n",
      "Создан labeled_data_general/8.json\n",
      "Создан labeled_data_general/9.json\n",
      "Создан labeled_data_general/10.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import librosa\n",
    "from datasets import load_dataset\n",
    "from transformers import ClapModel, ClapProcessor\n",
    "\n",
    "librispeech_dummy = load_dataset(\"hf-internal-testing/librispeech_asr_dummy\", \"clean\", split=\"validation\")\n",
    "audio_sample = librispeech_dummy[0]\n",
    "\n",
    "model = ClapModel.from_pretrained(\"laion/larger_clap_general\")\n",
    "processor = ClapProcessor.from_pretrained(\"laion/larger_clap_general\")\n",
    "\n",
    "def load_audio(filename, target_sr=48000):\n",
    "    audio, sr = librosa.load(filename, sr=target_sr)\n",
    "    return audio, sr\n",
    "\n",
    "def get_best_description(audio_file, descriptions):\n",
    "    audio, sr = load_audio(audio_file)\n",
    "    audio_inputs = processor(audios=audio, sampling_rate=sr, return_tensors=\"pt\", padding=True)\n",
    "    with torch.no_grad():\n",
    "        audio_features = model.get_audio_features(**audio_inputs)\n",
    "    text_inputs = processor(text=descriptions, return_tensors=\"pt\", padding=True)\n",
    "    with torch.no_grad():\n",
    "        text_features = model.get_text_features(**text_inputs)\n",
    "    similarities = torch.nn.functional.cosine_similarity(audio_features, text_features)\n",
    "    best_match_index = similarities.argmax().item()\n",
    "    best_match_description = descriptions[best_match_index]\n",
    "    return best_match_description\n",
    "\n",
    "with open('descriptions.json', 'r') as file:\n",
    "    descriptions = json.load(file)\n",
    "\n",
    "def process_folders(data_dir, labeled_dir, n, k):\n",
    "    os.makedirs(labeled_dir, exist_ok=True)\n",
    "\n",
    "    for folder_num in range(n, k + 1):\n",
    "        folder_name = f\"{folder_num:04d}\"\n",
    "        folder_path = os.path.join(data_dir, folder_name)\n",
    "\n",
    "        if not os.path.isdir(folder_path):\n",
    "            print(f\"Папка {folder_path} не существует, пропускаем.\")\n",
    "            continue\n",
    "\n",
    "        params_path = os.path.join(folder_path, \"params.json\")\n",
    "        audio_file = os.path.join(folder_path, \"prev.mp3\")\n",
    "\n",
    "        vital_file = None\n",
    "        for file_name in os.listdir(folder_path):\n",
    "            if file_name.endswith(\".vital\"):\n",
    "                vital_file = os.path.join(folder_path, file_name)\n",
    "                break\n",
    "\n",
    "        if not os.path.isfile(params_path) or not os.path.isfile(audio_file) or not vital_file:\n",
    "            print(f\"Отсутствует params.json, prev.mp3 или .vital файл в {folder_path}, пропускаем.\")\n",
    "            continue\n",
    "\n",
    "        with open(params_path, 'r') as file:\n",
    "            params = json.load(file)\n",
    "\n",
    "        try:\n",
    "            with open(vital_file, 'r') as file:\n",
    "                vital_content = file.read().strip()\n",
    "                if not vital_content:\n",
    "                    print(f\"Файл {vital_file} пуст, пропускаем.\")\n",
    "                    continue\n",
    "                vital_data = json.loads(vital_content)\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Файл {vital_file} не является валидным JSON, пропускаем.\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            best_description = get_best_description(audio_file, descriptions)\n",
    "            params[\"description\"] = best_description\n",
    "            params[\"preset\"] = vital_data\n",
    "\n",
    "            output_file = os.path.join(labeled_dir, f\"{folder_num}.json\")\n",
    "            with open(output_file, 'w') as file:\n",
    "                json.dump(params, file, indent=4)\n",
    "\n",
    "            print(f\"Создан {output_file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка при обработке {folder_path}: {e}\")\n",
    "\n",
    "data_directory = \"../data\"\n",
    "labeled_directory = \"labeled_data_general\"\n",
    "n = 1\n",
    "k = 10\n",
    "process_folders(data_directory, labeled_directory, n, k)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
